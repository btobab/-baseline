{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 比赛背景\n",
    "\n",
    "第三届中国AI+创新创业大赛由中国人工智能学会主办，半监督学习目标定位竞赛分赛道要求选手基于少量有标注数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。\n",
    "\n",
    "中国人工智能学会（Chinese Association for Artificial Intelligence，CAAI）成立于1981年，是经国家民政部正式注册的我国智能科学技术领域唯一的国家级学会，是全国性4A级社会组织，挂靠单位为北京邮电大学；是中国科学技术协会的正式团体会员，具有推荐“两院院士”的资格。\n",
    "\n",
    "中国人工智能学会目前拥有51个分支机构，包括43个专业委员会和8个工作委员会，覆盖了智能科学与技术领域。学会活动的学术领域是智能科学技术，活动地域是中华人民共和国全境，基本任务是团结全国智能科学技术工作者和积极分子通过学术研究、国内外学术交流、科学普及、学术教育、科技会展、学术出版、人才推荐、学术评价、学术咨询、技术评审与奖励等活动促进我国智能科学技术的发展，为国家的经济发展、社会进步、文明提升、安全保障提供智能化的科学技术服务。\n",
    "\n",
    "中国“AI+”创新创业大赛由中国人工智能学会发起主办，是为了配合实施创新驱动助力工程，深入开展服务企业技术创新活动，进一步提高我国文化建设和实践创新能力，展示智能科学与技术等相关学科建设的新经验、新成果，促进专业内涵的建设而发起的综合性大赛平台。\n",
    "\n",
    "飞桨PaddlePaddle作为中国首个自主研发、功能完备、开源开放的产业级深度学习平台，为本次比赛的参赛选手提供了集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体的一站式服务。百度大脑AI Studio作为官方指定且唯一的竞赛日常训练平台，为参赛选手提供高效的学习和开发环境，更有亿元Tesla V100算力免费赠送，助力选手取得优异成绩。\n",
    "\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简要介绍\n",
    "## 赛题背景\n",
    "半监督学习(Semi-Supervised Learning)是指通过大量无标记数据和少量有标记数据完成模型训练，解决具有挑战性的模式识别任务。近几年，随着计算硬件性能的提升和大量大规模标注数据集的开源，基于深度卷积神经网络(Deep Convolutional Neural Networks, DCNNs)的监督学习研究取得了革命性进步。然而，监督学习模型的优异性能要以大量标注数据作为支撑，可现实中获得数量可观的标注数据十分耗费人力物力(例如，获取像素级标注数据)。于是， 半监督学习逐渐成为深度学习领域的热门研究方向，只需要少量标记数据就可以完成模型训练过程，更适用于现实场景中的各种任务。\n",
    "## 比赛任务\n",
    "本次比赛要求选手基于少量有标签的数据训练模型，使分类网络具有目标定位能力，实现半监督目标定位任务。每- -位参赛选手仅可以使用ImageNet大型视觉识别竞赛(LSVRC)的训练集图像作为训练数据，其中有标签的训练数据仅可以使用大赛组委会提供的像素级标注。\n",
    "## 数据集介绍\n",
    "* 训练数据集包括50,000幅像素级标注的图像，共包含500个类，每个类100幅图像;\n",
    "* A榜测试数据集包括1 1,878幅无标注的图像;\n",
    "* B榜测试数据集包括10,989幅无标注的图像。\n",
    "## 评价指标\n",
    "本次比赛使用loU曲线作为评价指标，即利用预测的目标的定位概率图，计算不同阈值下预测结果与真实目标之间的IoU分数，最后取一个最高点作为最终的分数。在理想状态下，loU曲线最高值接近1.0,对应的阈值为255,因为阈值越高，目标对象与背景的对比度越高。\n",
    "##  网络介绍\n",
    "本示例简要介绍如何通过飞桨开源框架，实现图像分割。这里我们是采用了一个在图像分割领域比较熟知的U-Net网络结构，是一个基于FCN做改进后的一个深度学习网络，包含下采样（编码器，特征提取）和上采样（解码器，分辨率还原）两个阶段，因模型结构比较像U型而命名为U-Net。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 实现\n",
    "## 解压数据集\n",
    "默认解压到/data目录下，该目录会在每次进入环境时重置，但可以节省项目启动时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data95249/train_image.zip -d data/\r\n",
    "!unzip -oq /home/aistudio/data/data95249/train_50k_mask.zip -d data/\r\n",
    "!unzip -oq /home/aistudio/data/data95249/第一阶段test.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 导入所需库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "from paddle.io import Dataset,DataLoader\r\n",
    "from paddle.vision import transforms as T\r\n",
    "from paddle.nn import functional as F\r\n",
    "import cv2\r\n",
    "import paddle\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import paddle.nn as nn\r\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 定义超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#验证集的数量\r\n",
    "eval_num=1000\r\n",
    "#所有图像的大小\r\n",
    "image_size=(224,224)\r\n",
    "#训练图片路径\r\n",
    "train_images_path=\"data/train_image\"\r\n",
    "#标签路径\r\n",
    "label_images_path=\"data/train_50k_mask\"\r\n",
    "#测试图片路径\r\n",
    "test_images_path=\"data/val_image\"\r\n",
    "#批大小\r\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 获取所有图片的路径，并分为images和labels两组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#封装好的获取所有图片路径的函数\r\n",
    "from utils import get_path\r\n",
    "from utils import get_test_data\r\n",
    "#扩展一维，以便将images与labels合并\r\n",
    "images=np.expand_dims(np.array(get_path(train_images_path)),axis=1)\r\n",
    "labels=np.expand_dims(np.array(get_path(label_images_path)),axis=1)\r\n",
    "data=np.array(np.concatenate((images,labels),axis=1))\r\n",
    "#打乱数据，同时也不会影响images与labels的对应关系\r\n",
    "np.random.shuffle(data)\r\n",
    "#分割数据集\r\n",
    "train_data=data[:-eval_num,:]\r\n",
    "eval_data=data[-eval_num:,:]\r\n",
    "test_data=get_test_data(test_images_path)\r\n",
    "print(train_data.shape)\r\n",
    "print(eval_data.shape)\r\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 封装数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\r\n",
    "封装数据预处理函数，其中训练集与验证集、测试集的函数不同，\r\n",
    "训练集可以加入图像色彩的调整，但如果要加入水平翻转，缩放等方法，\r\n",
    "注意要同时对label也做同样处理\r\n",
    "验证集和测试集可以将图像色彩的调整去掉，因为加入数据预处理的原因是\r\n",
    "扩大特征空间，使得模型有更好的拟合能力，但验证集就没必要扩大数据的特征空间了\r\n",
    "'''\r\n",
    "train_transform=T.Compose([\r\n",
    "            T.Resize(image_size),\r\n",
    "            T.ColorJitter(0.1,0.1,0.1,0.1),\r\n",
    "            T.Transpose(),\r\n",
    "            T.Normalize(mean=0.,std=255.)\r\n",
    "        ])\r\n",
    "eval_transform=T.Compose([\r\n",
    "            T.Resize(image_size),\r\n",
    "            T.Transpose(),\r\n",
    "            T.Normalize(mean=0.,std=255.)\r\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 定义数据读取器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import show_images\r\n",
    "class ImageDataset(Dataset):\r\n",
    "    def __init__(self,path,transform):\r\n",
    "        super(ImageDataset, self).__init__()\r\n",
    "        self.path=path\r\n",
    "        self.transform=transform\r\n",
    "\r\n",
    "    def _load_image(self,path):\r\n",
    "        '''\r\n",
    "        该方法作用为通过路径获取图像\r\n",
    "        '''\r\n",
    "        img=cv2.imread(path)\r\n",
    "        img=cv2.resize(img,image_size)\r\n",
    "        return img\r\n",
    "\r\n",
    "    def __getitem__(self,index):\r\n",
    "        '''\r\n",
    "        这里之所以不对label使用transform，因为观察数据集发现label的图像矩阵主要为0或255\r\n",
    "        但偶尔也有0-1的值，所以要对label分情况处理\r\n",
    "        而对data都进行transform是因为data都是彩色图片，图像矩阵皆为0-255，所以可以统一处理\r\n",
    "        '''\r\n",
    "        path=self.path[index]\r\n",
    "        if len(path)==2:\r\n",
    "            data_path,label_path=path\r\n",
    "            data,label=self._load_image(data_path),self._load_image(label_path)\r\n",
    "            data,label=self.transform(data),label\r\n",
    "            label = label.transpose((2, 0, 1))\r\n",
    "            label = label[0, :, :]\r\n",
    "            label = np.expand_dims(label, axis=0)\r\n",
    "            if True in (label>1):\r\n",
    "                label=label/255.\r\n",
    "            label = label.astype(\"int64\")\r\n",
    "            return data,label\r\n",
    "        \r\n",
    "        if len(path)==1:\r\n",
    "            data=self._load_image(path[0])\r\n",
    "            data=self.transform(data)\r\n",
    "            return data\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.path)\r\n",
    "\r\n",
    "#获取数据读取器\r\n",
    "train_dataset=ImageDataset(train_data,train_transform)\r\n",
    "eval_dataset=ImageDataset(eval_data,eval_transform)\r\n",
    "test_dataset=ImageDataset(test_data,eval_transform)\r\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True,drop_last=True)\r\n",
    "eval_dataloader=DataLoader(eval_dataset,batch_size=batch_size,shuffle=True,drop_last=True)\r\n",
    "#观察数据读取是否正常\r\n",
    "data,label=next(train_dataloader())\r\n",
    "show_images([data[0],label[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from layer import Encoder,Residual\r\n",
    "class ImageNet(nn.Layer):\r\n",
    "    def __init__(self,num_classes):\r\n",
    "        super(ImageNet, self).__init__()\r\n",
    "        '''\r\n",
    "        encoders用于下采样，decoders用于上采样(实际上为pixelshuffle加下采样)\r\n",
    "        '''\r\n",
    "        channel=32\r\n",
    "        self.encoders=nn.Sequential(\r\n",
    "            nn.Conv2D(3,channel*2,5,2,padding=\"same\"),\r\n",
    "            nn.BatchNorm(channel*2),\r\n",
    "            nn.ReLU(),\r\n",
    "            Encoder(channel*2,channel*8),\r\n",
    "            Encoder(channel*8,channel*32)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.decoders=nn.Sequential(\r\n",
    "            nn.PixelShuffle(32),\r\n",
    "            Encoder(1,channel*2),\r\n",
    "            Encoder(channel*2,channel),\r\n",
    "            nn.Conv2D(channel,num_classes,5,padding=\"same\")\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self,input):\r\n",
    "        y=self.encoders(input)\r\n",
    "        y=self.decoders(y)\r\n",
    "        return y\r\n",
    "\r\n",
    "network=ImageNet(2)\r\n",
    "x=paddle.randn([1,3,224,224])\r\n",
    "y=network(x)\r\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用高层API开启训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir net_params/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=paddle.Model(network)\r\n",
    "opt=paddle.optimizer.Momentum(learning_rate=1e-4,parameters=model.parameters(),weight_decay=1e-2)\r\n",
    "model.prepare(opt, paddle.nn.CrossEntropyLoss(axis=1))\r\n",
    "model.fit(train_dataloader, eval_dataloader, epochs=10,verbose=2,save_dir=\"./net_params\",log_freq=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir data/val_label/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_path=\"./net_params/final\"\r\n",
    "save_dir=\"data/val_label\"\r\n",
    "model=ImageNet(2)\r\n",
    "model=paddle.Model(model)\r\n",
    "model.load(checkpoint_path)\r\n",
    "for i,img in tqdm(enumerate(test_dataset)):\r\n",
    "    img=paddle.to_tensor(img).unsqueeze(0)\r\n",
    "    predict=np.array(model.predict_batch(img)).squeeze(0).squeeze(0)\r\n",
    "    predict=predict.argmax(axis=0)\r\n",
    "    image_path=test_dataset.path[i]\r\n",
    "    path_lst=image_path[0].split(\"/\")\r\n",
    "    save_path=os.path.join(save_dir,path_lst[-1][:-5])+\".jpg\"\r\n",
    "    cv2.imwrite(save_path,predict*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "本基线重在为诸位划水员提供一个参考思路，因此没有进行进一步的优化，分数比较低。换言之，提升空间很大，涨点tips为：\n",
    "* 更换网络\n",
    "* 更换激活函数\n",
    "* 使用visualdl调参\n",
    "* 集成学习\n",
    "\n",
    "[最后欢迎大家三连关注一波丫](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/345331)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
